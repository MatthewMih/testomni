<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Visual Instruction Tuning">
  <meta name="keywords" content="multimodal chatbot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OmniFusion</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href=".static/css/index.css">
  <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }
</style>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">OmniFusion 
            <h3 class="title is-3 publication-title">A simple path to multimodal language models</h3>
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="link/to/habr" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Habr</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/ai-forever/OmniFusion" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon!)</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="t.me/bot_link" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Telegram Bot demo</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                  </a>
              </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop" id="gradio">
      <gradio-app src="https://omnifusion.demo.cc"></gradio-app>
    </div>
  </section> -->

  <section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks in the language domain, but the idea is less explored in the multimodal field.
              <ol type="1">
                <li><b>Multimodal Instruct Data</b>. <span style="font-size: 95%;">To create a multimodal model, we decided to take the best and most stable practices: a strong LLM, a powerful adapter, special tokens for new modalities and multi-stage instructional training with gradual unfreezing of LLM. </li>
                <li><b>OmniFusion Model</b>. <span style="font-size: 95%;">We introduce <it><b>OmniFusion</b></it>, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general-purpose visual and language understanding.</li>
                <li><b>Performance</b>. <span style="font-size: 95%;">Our early experiments show that OmniFusion demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4-V on unseen images/instructions.
                  When fine-tuned on <a href="https://scienceqa.github.io/">Science QA</a>, the synergy of OmniFusion accuracy of 92.53%.</li>
              </ol>  
           </p>
  
          </div>
        </div>
      </div>
        
    </div>
  </section>
 

<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> OmniFusion Architecture</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">

  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified"> 
        <p>
          OmniFusion connects pre-trained <a href="https://openai.com/research/clip">CLIP ViT-L/14</a> visual encoder and large language model, using a Transformer Encoder layer.   We consider a two-stage instruction-tuning procedure:
          <ul type="1">
            <li><b>Stage 1: Pre-training for Feature Alignment</b>. <span style="font-size: 95%;">Only the projection matrix is updated, based on a subset of CC3M and COCO.</span></li>
            <li><b>Stage 2: Fine-tuning End-to-End</b>. <span style="font-size: 95%;">Both the projection matrix and LLM are updated for two different use senarios: 
              <ul type="1">
                <li> <b>Visual Chat</b>: OmniFusion is fine-tuned on our generated multimodal instruction-following data for daily user-oriented applications. 
                <li> <b>Science QA</b>: OmniFusion is fine-tuned on this multimodal reasonsing dataset for the science domain.</span></li>
              </ul>  
          </ul>
        </p>
      </div>
      <centering>
        <div style="text-align: center;">
          <img id="teaser" width="70%" src="images/omnifusion_arch.png">     
        </div>
      </centering>           
    </div>
  </div>


</section>
  


<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/3515/3515174.png"> Performance</h2>
    </div>
  </div>



  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">


<section class="section">

  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"> Examples on Visual Instruction Following</h2>
    </div>
  </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
         <h2 class="title is-4">Visual Reasoning on two examples from <a href="https://arxiv.org/abs/2303.08774">OpenAI GPT-4 Technical Report</a></h2>
      </div>
      </div>  

    <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <img id="teaser" width="35%" src="images/cmp_ironing.png">
      <img id="teaser" width="38%" src="images/cmp_chicken_nugget.png">
    </div>
    </div>  

  

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
         <h2 class="title is-4">Optical character recognition (OCR)</a></h2>
      </div>
      </div>  

    <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths" style="display: flex; align-items: flex-start; justify-content: center;">
        <img id="teaser" width="32%" src="images/ocr/omnifusion_example_cvpr2023.png">
        <img id="teaser" width="32%" src="images/ocr/omnifusion_example_cvinw_logo.png">
        <img id="teaser" width="32%" src="images/ocr/example_omnifusion_exmaple.png">
    </div>
    </div>  

  <div class="container mt-5">
    <!-- <h2 class="text-center mb-5">Who's GPT-4's favorite? Battles between State-of-the-Art Chatbots</h2> -->
    <!-- Selection -->
    <div class="form-row" style="justify-content: flex-end;">
      <div class="form-group col-md-1">
        <div class="col-md-2" style="width: 100%"><label>&nbsp;</label></div>
        <div class="btn-group" role="group" aria-label="Left and Right Controller"
          style="width: 100%;align-items: flex-end;justify-content: center;flex-direction: row;display: flex;">
          <button type="button" class="form-control btn btn-primary" id="prev-question"><i
              class="material-icons">keyboard_arrow_left</i></button>
          <button type="button" class="form-control btn btn-primary" id="next-question"><i
              class="material-icons">keyboard_arrow_right</i></button>

        </div>
      </div>
    </div>

    <!-- Question Card -->
    <div style="display: flex; justify-content: center; align-items: center;">
      <div class="card mb-4" style="width: 100%; display: flex; align-items: center;">
        <!-- <p><b>Description:</b> Monalisa is a famous painting by Leonardo da Vinci. </p> -->

        <div class="card-body" id="selected-question" style="display: flex; height: 80vh;">
          <div class="chat-history">
            <!-- Add your chat messages here -->
          </div>

        </div>
      </div>
    </div>

  </div>
</section>

  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
  </code></pre>
    </div>
  </section> -->
  
  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgement</h2>
      <p>
        This website is adapted from <a
        href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>

      <p>
<b>Usage and License Notices</b>: The data, code and checkpoint is intended and licensed for research use only. They are also restricted to uses that follow the license agreement of CLIP. 
</p>

    </div>
  </section>

  <script>
    // Handle message showing
    function createChatRow(sender, text, imageSrc) {
      var article = document.createElement("article");
      article.className = "media"

      var figure = document.createElement("figure");
      figure.className = "media-left";

      var span = document.createElement("span");
      span.className = "icon is-large";

      var icon = document.createElement("i");
      icon.className = "fas fas fa-2x" + (sender === "User" ? " fa-user " : sender === "OmniFusion" ? " fa-robot" : "");

      var media = document.createElement("div");
      media.className = "media-content";

      var content = document.createElement("div");
      content.className = "content";

      var para = document.createElement("p");

      // wrap text in pre tag to preserve whitespace and line breaks
      var pre_text = document.createElement("pre");
      pre_text.style = "background-color: white; font-size: 18px; font-family: Arial; padding: 0; margin: 0; white-space: pre-wrap; word-wrap: break-word;";
      var paraText = document.createTextNode(text);
      pre_text.appendChild(paraText);

      var strong = document.createElement("strong");
      strong.innerHTML = sender;
      var br = document.createElement("br");

      para.appendChild(strong);
      para.appendChild(br);
      para.appendChild(pre_text);

      // Add image if imageSrc is provided
      if (imageSrc) {
        var img = document.createElement("img");
        img.src = imageSrc;
        img.style = "max-width: 100%; max-height: 300px;"; // Adjust the style as needed
        para.appendChild(img);
      }

      content.appendChild(para);
      media.appendChild(content);
      span.appendChild(icon);
      figure.appendChild(span);
      if (sender !== "Description") {
        article.appendChild(figure);
      };
      article.appendChild(media);
      return article;
    }

    function addMessageToChatHistory(sender, message, imageSrc) {
      const chatHistory = document.querySelector('.chat-history');
      const chatRow = createChatRow(sender, message, imageSrc);
      chatHistory.appendChild(chatRow);
      chatHistory.scrollTop = chatHistory.scrollHeight;
    }

    function clearChatHistory() {
      const chatHistory = document.querySelector('.chat-history');
      chatHistory.innerHTML = "";
    }

    // 
    const conversations = [
      {
        "description": "spb",
        "turns": [
          // ["Description", "Please read the description and answer the question."],
          ["User", "", "static/images/spb-map.png"],
          ["User", "What is the city depicted the map?​"],
          ["OmniFusion", "The map depicts St. Petersburg."]
        ]
      },
      {
        "description": "bread",
        "turns": [
          ["User", "", "static/images/bread.jpg"],
          ["User", "Is it suitable to eat?"],
          ["OmniFusion", "No, it is not suitable to eat."],
          ["User", "Why not? Explain please"],
          ["OmniFusion", "The piece of toast on the plate is covered in mold, when is a sign of food spoilage or contamination. Eating moldy food can lead to various health issues, such as allergic reactions, digestive problems, and infections. In this case, it is best to discard the moldy toast and avoid consuming it."]
          ]
      },
      {
        "description": "design",
        "turns": [
          // ["Description", "Please read the description and answer the question."],
          ["User", "", "static/images/design.png"],
          ["User", "In which direction is the master bedroom located? (choose from North, South, West, East)​"],
          ["OmniFusion", "The master bedroom is located in the South direction."],
          ["User", "In which direction is the master bedroom located? (choose from North, South, West, East)​"],
          ["OmniFusion", "The bedroom is located in the upper right corner of the image."]
        ]
      },
      {
        "description": "iqtest",
        "turns": [
          // ["Description", "Please read the description and answer the question."],
          ["User", "", "static/images/iqtest.png"],
          ["User", "Here are three sub images arranged in a 2-by-2 matrix. First, look at the two images in the first column, in the top left and " +
          "bottom left. Then, find out the pattern in the first column " +
          "based on the left two images. Next, use the found pattern " + 
          "and the image in the top right to infer the missing figure. " +
          "Finally, describe what would the missing image look like?​"],
          ["OmniFusion", "The missing image in the top right corner of the matrix would be a star with a single point, which is the pattern observed in the first column. This pattern can be inferred from the two images in the top left and bottom left corners of the matrix. The missing image would be a star with a single point, which completes the pattern of stars in the first column."]
        ]
      },
    ];

    // The current image index
    let currentIndex = 0;

    // The function to update the displayed chat history
    function update_dialog_demo() {
      // Clear the chat history
      clearChatHistory();

      for (let i = 0; i < conversations[currentIndex].turns.length; i++) {
        if (conversations[currentIndex].turns[i].length == 2) {
          addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1]);
        }
        else {
          addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1], conversations[currentIndex].turns[i][2]);
        }
      }

      // scroll to the top of the chat history
      document.querySelector('.chat-history').scrollTop = 0;
    }

    // Initialize the displayed image
    update_dialog_demo();

    // Event listeners for the buttons
    document.getElementById('prev-question').addEventListener('click', () => {
      currentIndex = (currentIndex - 1 + conversations.length) % conversations.length;
      update_dialog_demo();
    });

    document.getElementById('next-question').addEventListener('click', () => {
      currentIndex = (currentIndex + 1) % conversations.length;
      update_dialog_demo();
    });


  </script>

</body>

</html>
